{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STARTING SNORKEL PROGRAM\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "## POSTGRES DATABASE CONN FOR SNORKEL \n",
    "os.environ['SNORKELDB']= \"postgres://postgres:password123@localhost:5432/snorkel\"\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING THE MINERAL DICTIONARY FOR MINERAL CANDIDATE EXTRACTOR\n",
    "mineral_words    = {'halite', 'sylvite','hydrohalite','bischofite', 'antacitite','carnallite','tachyhydrite','rhinneite','kainite','thermonatrite','soda','nahcolite','anhydrite','bassanite', 'gypsum' , 'kieserite', 'saderite', 'epsomite', 'thernadite', 'mirabillte', 'celestine', 'glaserite', 'vanthoffite', 'bleodite', 'loeweite', 'langbeinite' , 'leonine', 'glauberite', 'syngenite', 'polyhalite', 'northupite', 'burette', 'techie', 'hanksite', 'lautarite', 'kernite', 'borax', 'colemanite' }              \n",
    "mineral_wordss   = {'halite', 'sylvite','hydrohalite','bischofite', 'antacitite','carnallite','tachyhydrite','rhinneite','kainite','thermonatrite','soda','nahcolite','anhydrite','bassanite', 'gypsum' , 'kieserite', 'saderite', 'epsomite', 'thernadite', 'mirabillte', 'celestine', 'glaserite', 'vanthoffite', 'bleodite', 'loeweite', 'langbeinite' , 'leonine', 'glauberite', 'syngenite', 'polyhalite', 'northupite', 'burette', 'techie', 'hanksite', 'lautarite', 'kernite', 'borax', 'colemanite' }              \n",
    "mineral_formulas = {'NaCl','KCl','K2SO4','CaSO4','MgCl2','CaCl2','4KCl','4MgSO4','MgSO4','CaCO3','Na2CO3','NaHCO3','3MgCO3','K2SO4','Na2SO4','3Na2SO4','SrSO4','NaSO4','2Na2CO3'}\n",
    "mineral_words    = list(mineral_words)+list(mineral_formulas)\n",
    "mineral_wordss   = list(mineral_wordss)+list(mineral_formulas)\n",
    "mineral_dict     = dict(zip(mineral_words,mineral_wordss))\n",
    "\n",
    "mineral_words    = {'halite', 'sylvite','hydrohalite','bischofite', 'antacitite','carnallite','tachyhydrite','rhinneite','kainite','thermonatrite','soda','nahcolite','anhydrite','bassanite', 'gypsum' , 'kieserite', 'saderite', 'epsomite', 'thernadite', 'mirabillte', 'celestine', 'glaserite', 'vanthoffite', 'bleodite', 'loeweite', 'langbeinite' , 'leonine', 'glauberite', 'syngenite', 'polyhalite', 'northupite', 'burette', 'techie', 'hanksite', 'lautarite', 'kernite', 'borax', 'colemanite' }              \n",
    "mineral_formulas = {'NaCl','KCl','K2SO4','CaSO4','MgCl2','CaCl2','4KCl','4MgSO4','MgSO4','CaCO3','Na2CO3','NaHCO3','3MgCO3','K2SO4','Na2SO4','3Na2SO4','SrSO4','NaSO4','2Na2CO3'}\n",
    "mineral_set    = set(list(mineral_words)+list(mineral_formulas))\n",
    "\n",
    "target_words ={ 'halite', 'sylvite','hydrohalite','bischofite', 'antacitite','carnallite','tachyhydrite','rhinneite','kainite','thermonatrite','soda','nahcolite','anhydrite','bassanite', 'gypsum' , 'kieserite', 'saderite', 'epsomite', 'thernadite', 'mirabillte', 'celestine', 'glaserite', 'vanthoffite', 'bleodite', 'loeweite', 'langbeinite' , 'leonine', 'glauberite', 'syngenite', 'polyhalite', 'northupite', 'burette', 'techie', 'hanksite', 'lautarite', 'kernite', 'borax', 'colemanite','NaCl','KCl','K2SO4','CaSO4','MgCl2','CaCl2','4KCl','4MgSO4','MgSO4','CaCO3','Na2CO3','NaHCO3','3MgCO3','K2SO4','Na2SO4','3Na2SO4','SrSO4','NaSO4','2Na2CO3'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PULLING EXISTING STRATIGRAPHIC NAMES FROM MACROSTRAT FOR MINERAL CANDIDATE EXTRACTOR\n",
    "import urllib\n",
    "import json\n",
    "## Making the Stratigraphic \n",
    "request = urllib.urlopen('https://macrostrat.org/api/v2/defs/strat_names?all')\n",
    "data = json.loads(request.read())\n",
    "\n",
    "strat_flags = {\"Group\", \"Formation\", \"Member\", \"Supergroup\", \"Bed\", \"Subgroup\",\"Gp.\", \"Fm.\", \"Mbr.\", \"SGp.\", \"Gp\", \"Fm\", \"Mbr\", \"SGp\"}    \n",
    "lith_flags = {\"Dolomite\",\"Dolostone\",\"Limestone\",\"Sandstone\",\"Shale\",\"Conglomerate\",\"Chert\"}\n",
    "strat_flags = list(strat_flags)+list(lith_flags)\n",
    "#FULL STRAT NAME\n",
    "strat_dict_long = { r['strat_name_long'] for r in data['success']['data'] }\n",
    "\n",
    "#ABBREVIATED STRAT NAME - V1\n",
    "strat_dict_abV1 = { r['strat_name'] + ' ' + r['rank'] for r in data['success']['data'] }\n",
    "\n",
    "#ABBREVIATED STRAT NAME - V2\n",
    "strat_dict_abV2 = { r['strat_name'] + ' ' + r['rank'] + '.' for r in data['success']['data'] }\n",
    "\n",
    "#LITHOLOGY STRAT NAMES\n",
    "request = urllib.urlopen('https://macrostrat.org/api/v2/defs/lithologies?all')\n",
    "lithologies = json.loads(request.read())\n",
    "lithologies=[l['name'].capitalize() for l in lithologies['success']['data']]\n",
    "\n",
    "strat_dict_short = { r['strat_name'] for r in data['success']['data'] }\n",
    "\n",
    "strat_dict_lith=set()\n",
    "for r in strat_dict_short:\n",
    "    if r.split(' ')[-1] in lithologies:\n",
    "        strat_dict_lith.add(r)\n",
    "        \n",
    "strat_dict    =set(list(strat_dict_long)+list(strat_dict_abV1)+list(strat_dict_abV2)+list(strat_dict_lith)+list(strat_flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFYING CANDIDATE CLASS OF A MINERAL WORD AND A STRAT WORD \n",
    "from snorkel.models import candidate_subclass\n",
    "Mineral   = candidate_subclass('Mineral' ,['mineral_name','strat_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFYING PARAMATERS FOR MINERAL CANDIDATE EXTRACTOR\n",
    "from snorkel.candidates import Ngrams,CandidateExtractor\n",
    "from snorkel.matchers import DictionaryMatch, RegexMatchSpan\n",
    "\n",
    "ngram_mineral = Ngrams(n_max=1)\n",
    "ngram_strat   = Ngrams(n_max=9)\n",
    "\n",
    "mineral_matcher    = DictionaryMatch(ignore_case=True, d=mineral_dict)\n",
    "strat_matcher      = DictionaryMatch(d=strat_dict,ignore_case=False,longest_match_only=True)\n",
    "mineral_extractor  = CandidateExtractor(Mineral, [ngram_mineral, ngram_strat], [mineral_matcher, strat_matcher])\n",
    "\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "cand_extractor = CandidateExtractor(Mineral, [ngram_mineral,ngram_strat], [mineral_matcher,strat_matcher],\n",
    "                        symmetric_relations=True, nested_relations=False, self_relations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/922 [00:00<00:50, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of Training Documents: 117\n",
      "Numer of Development Documents: 37\n",
      "Numer of Testing Documents: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 922/922 [02:50<00:00, 16.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "df1 = pd.read_csv('sentences_parition3.tsv',sep='\\t')\n",
    "docids = df1['mineral_stable_id'].to_list()\n",
    "splits = df1['split'].to_list()\n",
    "\n",
    "train_docids = set()\n",
    "dev_docids = set()\n",
    "test_docids = set()\n",
    "\n",
    "for doc, s in zip(docids,splits):\n",
    "    splitter = doc.split('::')\n",
    "    docid = splitter[0]\n",
    "    if s == 0:\n",
    "        train_docids.add(docid)\n",
    "    elif s == 1:\n",
    "        dev_docids.add(docid)\n",
    "    elif s == 2:\n",
    "        test_docids.add(docid)\n",
    "    \n",
    "        \n",
    "print('Numer of Training Documents: {0}'.format(len(train_docids)))\n",
    "print('Numer of Development Documents: {0}'.format(len(dev_docids)))\n",
    "print('Numer of Testing Documents: {0}'.format(len(test_docids)))\n",
    "\n",
    "from snorkel.models import Document\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "\n",
    "\n",
    "train_sents = set()\n",
    "dev_sents = set()\n",
    "test_sents = set()\n",
    "gdd_sents = set()\n",
    "\n",
    "#Looping through docs and partitioning them into training, development, and testing sets\n",
    "for doc in tqdm(docs):\n",
    "    for s in doc.sentences:\n",
    "        if s.document.name in train_docids:\n",
    "            train_sents.add(s)\n",
    "        elif s.document.name in dev_docids:\n",
    "            dev_sents.add(s)\n",
    "        elif s.document.name in test_docids:\n",
    "            test_sents.add(s)\n",
    "        else:\n",
    "            gdd_sents.add(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/198991 [00:00<12:18, 269.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198991/198991 [08:29<00:00, 390.49it/s]\n",
      "  0%|          | 39/78978 [00:00<03:28, 378.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of candidates:', 3750L)\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78978/78978 [03:00<00:00, 438.61it/s]\n",
      "  0%|          | 32/82798 [00:00<04:19, 319.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of candidates:', 1063L)\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82798/82798 [02:47<00:00, 495.56it/s]\n",
      "  0%|          | 82/874718 [00:00<17:50, 816.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of candidates:', 989L)\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874718/874718 [23:22<00:00, 623.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of candidates:', 1111L)\n",
      "Elapsed Time: 2259.73490906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i, sents in enumerate([train_sents, dev_sents, test_sents,gdd_sents]):\n",
    "    cand_extractor.apply(sents, split = i)\n",
    "    print(\"Number of candidates:\", session.query(Mineral).filter(Mineral.split == i).count())\n",
    "elapsed_time = time.time() - start_time\n",
    "print 'Elapsed Time: {0}'.format(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from builtins import *\n",
    "\n",
    "import pandas as pd\n",
    "from snorkel.models import StableLabel\n",
    "from snorkel.db_helpers import reload_annotator_labels\n",
    "\n",
    "\n",
    "\n",
    "FPATH = 'gold_labels1.tsv'\n",
    "\n",
    "def load_external_labels(session, candidate_class, annotator_name='gold'):\n",
    "    gold_labels = pd.read_csv(FPATH, sep=\"\\t\")\n",
    "    for index, row in gold_labels.iterrows():    \n",
    "\n",
    "        # We check if the label already exists, in case this cell was already executed\n",
    "        context_stable_ids = \"~~\".join([row['mineral_name'], row['strat_name']])\n",
    "        query = session.query(StableLabel).filter(StableLabel.context_stable_ids == context_stable_ids)\n",
    "        query = query.filter(StableLabel.annotator_name == annotator_name)\n",
    "        if query.count() == 0:\n",
    "            session.add(StableLabel(\n",
    "                context_stable_ids=context_stable_ids,\n",
    "                annotator_name=annotator_name,\n",
    "                value=row['value']))\n",
    "                    \n",
    "        # Because it's a symmetric relation, load both directions...\n",
    "        context_stable_ids = \"~~\".join([row['strat_name'], row['mineral_name']])\n",
    "        query = session.query(StableLabel).filter(StableLabel.context_stable_ids == context_stable_ids)\n",
    "        query = query.filter(StableLabel.annotator_name == annotator_name)\n",
    "        if query.count() == 0:\n",
    "            session.add(StableLabel(\n",
    "                context_stable_ids=context_stable_ids,\n",
    "                annotator_name=annotator_name,\n",
    "                value=row['value']))\n",
    "\n",
    "    # Commit session\n",
    "    session.commit()\n",
    "\n",
    "    # Reload annotator labels\n",
    "    reload_annotator_labels(session, candidate_class, annotator_name, split=0, filter_label_split=False)\n",
    "    reload_annotator_labels(session, candidate_class, annotator_name, split=1, filter_label_split=False)\n",
    "    reload_annotator_labels(session, candidate_class, annotator_name, split=2, filter_label_split=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 3750\n",
      "AnnotatorLabels created: 1059\n",
      "AnnotatorLabels created: 987\n",
      "CPU times: user 4min 19s, sys: 4.85 s, total: 4min 23s\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%time missed = load_external_labels(session, Mineral, annotator_name='gold')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
